@article{buen2005,
  title = {Comparing the Sound o f Golden Age and Modern Violins: Long-Time-Average Spectra},
  shorttitle = {Comparing the Sound o f Golden Age and Modern Violins},
  author = {Buen, Anders},
  date = {2005-07-01},
  journaltitle = {Proceedings from BNAM},
  abstract = {Recordings of the sound spectra produced by violins made by Antonio Stradivari (1 5), Giuseppe Guameri del Gesu (1 5), and 18 contemporary makers were analyzed and compared In general, the sound produced by the 30 violins crafted by the two great Italian masters is very strong in the region from about C\#q to G4 (274 to 41 0 Hz) and signij7cantly stronger in the highrfiequency regionfrom to G7 (2901 to 3073 Hz) and from B, to G\#8 (3868 to 6494 Hz). The particular group of modem violins we ana-lyzed had relatively equal or stronger fundamentals at very low notes below Cq ({$<$}260 Hz), in the mid-frequency region A4 to F, (440 to 2793 Hz), and at very high frequencies ({$>$}6.5 H z) . Overall, the sound produced by the violins of Stradivari and Guameri was darker, less nasal, somewhat stronger in the high-brightness region, and possibly less sharp than was typical of the modem violins.},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/PCY2UA9Z/Buen - 2005 - COMPARING THE SOUND O F GOLDEN AGE AND MODERN VIOL.pdf}
}

@article{deng2008,
  title = {A {{Study}} on {{Feature Analysis}} for {{Musical Instrument Classification}}},
  author = {Deng, Jeremiah D. and Simmermacher, Christian and Cranefield, Stephen},
  date = {2008-04},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume = {38},
  number = {2},
  pages = {429--438},
  issn = {1941-0492},
  doi = {10.1109/TSMCB.2007.913394},
  url = {https://ieeexplore.ieee.org/abstract/document/4436069},
  urldate = {2025-01-10},
  abstract = {In tackling data mining and pattern recognition tasks, finding a compact but effective set of features has often been found to be a crucial step in the overall problem-solving process. In this paper, we present an empirical study on feature analysis for recognition of classical instrument, using machine learning techniques to select and evaluate features extracted from a number of different feature schemes. It is revealed that there is significant redundancy between and within feature schemes commonly used in practice. Our results suggest that further feature analysis research is necessary in order to optimize feature selection and achieve better results for the instrument recognition problem.},
  eventtitle = {{{IEEE Transactions}} on {{Systems}}, {{Man}}, and {{Cybernetics}}, {{Part B}} ({{Cybernetics}})},
  keywords = {Classification algorithms,Data mining,Feature extraction,feature selection,Humans,Instruments,Machine learning,MPEG 7 Standard,Multiple signal classification,music,Music information retrieval,pattern classification,Signal processing}
}

@inproceedings{eronen2000,
  title = {Musical Instrument Recognition Using Cepstral Coefficients and Temporal Features},
  booktitle = {2000 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}. {{Proceedings}} ({{Cat}}. {{No}}.{{00CH37100}})},
  author = {Eronen, A. and Klapuri, A.},
  date = {2000-06},
  volume = {2},
  pages = {II753-II756 vol.2},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2000.859069},
  url = {https://ieeexplore.ieee.org/document/859069},
  urldate = {2024-05-07},
  abstract = {In this paper, a system for pitch independent musical instrument recognition is presented. A wide set of features covering both spectral and temporal properties of sounds was investigated, and their extraction algorithms were designed. The usefulness of the features was validated using test data that consisted of 1498 samples covering the full pitch ranges of 30 orchestral instruments from the string, brass and woodwind families, played with different techniques. The correct instrument family was recognized with 94\% accuracy and individual instruments in 80\% of cases. These results are compared to those reported in other work. Also, utilization of a hierarchical classification framework is considered.},
  eventtitle = {2000 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}. {{Proceedings}} ({{Cat}}. {{No}}.{{00CH37100}})},
  keywords = {Algorithm design and analysis,Cepstral analysis,Data mining,Instruments,Laboratories,Multiple signal classification,Music,printed,read,Signal analysis,Signal processing algorithms,Testing},
  file = {/home/hugo/Zotero/storage/RH2LRRU2/859069.html}
}

@article{essid2006,
  title = {Musical Instrument Recognition by Pairwise Classification Strategies},
  author = {Essid, S. and Richard, G. and David, B.},
  date = {2006-07},
  journaltitle = {IEEE Transactions on Audio, Speech and Language Processing},
  shortjournal = {IEEE Trans. Audio Speech Lang. Process.},
  volume = {14},
  number = {4},
  pages = {1401--1412},
  issn = {1558-7916},
  doi = {10.1109/TSA.2005.860842},
  url = {http://ieeexplore.ieee.org/document/1643665/},
  urldate = {2024-08-30},
  abstract = {Musical instrument recognition is an important aspect of music information retrieval. In this paper, statistical pattern recognition techniques are utilized to tackle the problem in the context of solo musical phrases. Ten instrument classes from different instrument families are considered. A large sound database is collected from excerpts of musical phrases acquired from commercial recordings translating different instrument instances, performers, and recording conditions. More than 150 signal processing features are studied including new descriptors. Two feature selection techniques, inertia ratio maximization with feature space projection and genetic algorithms are considered in a class pairwise manner whereby the most relevant features are fetched for each instrument pair. For the classification task, experimental results are provided using Gaussian mixture models (GMMs) and support vector machines (SVMs). It is shown that higher recognition rates can be reached with pairwise optimized subsets of features in association with SVM classification using a radial basis function kernel.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/HEUVST96/Essid et al. - 2006 - Musical instrument recognition by pairwise classif.pdf}
}

@article{fritz2019,
  title = {The {{Bilbao}} Project : {{How}} Violin Makers Match Backs and Tops to Produce Particular Sorts of Violins},
  author = {Fritz, Claudia and Stoppani, George and Igartua, Unai and Rico, Roberto Jardón and Arroitajauregi, Ander and Artol, Luis},
  date = {2019},
  abstract = {The Bilbao project aims at answering this question by relating intrinsic characteristics of the materials (wood density and stiffness) and some geometric characteristics of the violin’s constituent parts (thicknesses of the plates) with the tonal qualities of the complete violins. To this end, six instruments were carefully built: three instruments with normal backs, each paired with a pliant (thin), normal, or resistant (thick) top ; similarly, three with normal tops, each paired with a pliant, normal, or resistant back. The two examples of normal top paired with normal back serve as a control. Wood for tops and backs were closely matched in density and sound speeds – all tops and backs from the same trees. Greater control was achieved by having all plates and scrolls cut by CNC routers. The outside surface was not changed during the experiment, as the graduation was performed entirely on the inside surface. In addition, structural measurements were taken at many steps during the building process and the instruments were then assessed during playing and listening tests. These six instruments constitute therefore an unprecedented set of carefully controlled and documented violins, and offer an incredible opportunity for conducting various analyses and correlations.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/AEFQS6F7/Fritz et al. - The Bilbao project  How violin makers match backs and tops to produce particular sorts of violins.pdf}
}

@inproceedings{fritz2021,
  title = {The {{Bilbao}} Project: Searching for Relationships between Sound and Playing Properties of Violins with Their Construction Parameters},
  shorttitle = {The {{Bilbao}} Project},
  booktitle = {Conference on {{Sound Perception}}},
  author = {Fritz, Claudia and Salvador, Víctor and Stoppani, George},
  date = {2021-09-03},
  url = {https://hal.science/hal-03446713},
  urldate = {2024-06-14},
  abstract = {The Bilbao project aimed at relating intrinsic characteristics of the materials (wood density and stiffness) and some geometric characteristics of the violin's constituent part (thicknesses of the plates) with the tonal qualities of the complete violins. To this end, six instruments were carefully built at the Bilbao making school: three instruments with normal backs, each paired with a pliant (thin), normal or resistant (thick) top; similarly, three with normal tops, each paired with a pliant, normal or resistant back. The two examples of normal top paired with normal back serve as a control. Wood for tops and backs were closely matched in density and sound speeds-all tops and backs from the same trees. Greater control was achieved by having all plates and scrolls cut by CNC routers, using the Huberman Stradivari model. The outside surface was not changed as the graduation was performed entirely on the inside surface. In addition, another six instruments were built by six established makers, following a similar procedure but with less constraints on the choice of wood (not the same trees as for the Bilbao set though a similar density was imposed) and on the graduation of the routed plates which was left totally free (but ended in the same range of thicknesses). Finally, another violin built with a very different profile but made by one of the established maker was added to the pool as an outlier. These thirteen violins were then evaluated by twenty players during a free categorisation task and by about 70 listeners (31 violin makers, 26 bow players and 15 others) during a listening test in the Bilbao conservatory auditorium. The tests show very large differences in terms of timbre, playability and volume between the violins, and these differences will be discussed in the light of their construction parameters.},
  eventtitle = {Conference on {{Sound Perception}}},
  langid = {english},
  file = {/home/hugo/Zotero/storage/F4E43HWS/hal-03446713v1.html}
}

@inproceedings{gabrielsson2007,
  title = {An Analysis of Long-Time-Average-Spectra of Twentytwo Quality-Rated Violins},
  author = {Gabrielsson, A. and Jansson},
  date = {2007},
  url = {https://www.semanticscholar.org/paper/An-analysis-of-long-time-average-spectra-of-violins-Gabrielsson-Jansson/786c0e0b14dd4d005e4b15786936c5070d80dc0b},
  urldate = {2024-07-15},
  abstract = {LongTime-Average-Spectra (L TAS:es) were recorded of 22 qualityrated violins. The LTAS:es were analyzed by four different methods: weight functions, factor analysis (FA), multidimensional scaling (MDS), and separate correlation analysis. The average difference between the instruments rated highest and lowest was t r ied a s a function weighting tonal quality. This weight function explained 64 70 of the variance of the tonal quality-ratings. Factor analysis and multidimensional scaling in five factor s/dimensions gave approximately the same solutions. The solutions accounted for 74 70 and 44 ' \$0 respec t ive ly of the variance of the LTAS:es and for 74 70 and 69 70 respectively of the variance of the tonal quality-ratings. The variations in certain res t r ic ted frequency regions selected by correlation analysis accounted for 7 1-84 70 of the variance in the tonal quality-ratings. The different methods imply that "strong" f r e quency components a r e favorable in a low frequency region and in a middle high frequency region, while "weak" frequency components a r e favorable in a high frequency region and in a l imited middle frequency region. The resu l t s seem reliable, a t l eas t for the selected instruments.},
  file = {/home/hugo/Zotero/storage/ZV7QB7FY/Gabrielsson and Jansson - 2007 - An analysis of long-time-average-spectra of twenty.pdf}
}

@article{giraldo2019,
  title = {Automatic {{Assessment}} of {{Tone Quality}} in {{Violin Music Performance}}},
  author = {Giraldo, Sergio and Waddell, George and Nou, Ignasi and Ortega, Ariadna and Mayor, Oscar and Perez, Alfonso and Williamon, Aaron and Ramirez, Rafael},
  date = {2019-03-14},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {10},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.00334},
  url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.00334/full},
  urldate = {2024-10-08},
  abstract = {{$<$}p{$>$}The automatic assessment of music performance has become an area of increasing interest due to the growing number of technology-enhanced music learning systems. In most of these systems, the assessment of musical performance is based on pitch and onset accuracy, but very few pay attention to other important aspects of performance, such as sound quality or timbre. This is particularly true in violin education, where the quality of timbre plays a significant role in the assessment of musical performances. However, obtaining quantifiable criteria for the assessment of timbre quality is challenging, as it relies on consensus among the subjective interpretations of experts. We present an approach to assess the quality of timbre in violin performances using machine learning techniques. We collected audio recordings of several tone qualities and performed perceptual tests to find correlations among different timbre dimensions. We processed the audio recordings to extract acoustic features for training tone-quality models. Correlations among the extracted features were analyzed and feature information for discriminating different timbre qualities were investigated. A real-time feedback system designed for pedagogical use was implemented in which users can train their own timbre models to assess and receive feedback on their performances.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Automatic assessment of music,machine learning,music performance,Tone quality,violin performance},
  file = {/home/hugo/Zotero/storage/JVJCR8GU/Giraldo et al. - 2019 - Automatic Assessment of Tone Quality in Violin Music Performance.pdf}
}

@article{gonzalez2018,
  title = {A Machine Learning Approach to Violin Timbre Quality Classification},
  author = {González, Pedro Lladó},
  date = {2018},
  langid = {english},
  file = {/home/hugo/Zotero/storage/IKR5E9E2/González - A machine learning approach to violin timbre quali.pdf}
}

@inproceedings{jansson2007,
  title = {Long-Time-Average-Spectra Applied to Analysis of Music},
  author = {Jansson},
  date = {2007},
  url = {https://www.semanticscholar.org/paper/Long-time-average-spectra-applied-to-analysis-of-Jansson/71befcd4282e07f079db20b2b33e160b33dfcd0c},
  urldate = {2024-07-15},
  abstract = {Semantic Scholar extracted view of "Long-time-average-spectra applied to analysis of music" by Jansson},
  file = {/home/hugo/Zotero/storage/PQCQ8MHP/Jansson - 2007 - Long-time-average-spectra applied to analysis of m.pdf}
}

@inproceedings{lukasik2003,
  title = {{{AMATI}} - {{Multimedia Database}} of {{Violin Sounds}}},
  author = {Lukasik, Ewa},
  date = {2003-01-01}
}

@article{lukasik2010,
  title = {Long {{Term Cepstral Coefficients}} for {{Violin Identification}}},
  author = {Lukasik, E.},
  date = {2010-05-01},
  journaltitle = {Journal of The Audio Engineering Society},
  url = {https://www.semanticscholar.org/paper/Long-Term-Cepstral-Coefficients-for-Violin-Lukasik/1078124310e55d7f734e2cead68f0d1ad7ccf511},
  urldate = {2024-04-24},
  abstract = {Cepstral coefficients in mel scale proved to be efficient features for speaker and musical instrument recognition. In this paper Long Term Cepstral Coefficients  LTCCs  of solo musical phrases are used as features for identification of individual violins. LTCC represents the envelope of LTAS  Long Term Average Spectrum in linear scale useful to characterize the subtleties of violin sound in frequency domain. Results of the classification of 60 instruments are presented and discussed. It was shown, that if the experts knowledge is applied to analyze violin sound, the results may be promising.},
  keywords = {printed,read},
  file = {/home/hugo/Zotero/storage/RI2R6L4S/Lukasik - 2010 - Long Term Cepstral Coefficients for Violin Identif.pdf}
}

@article{martin1998,
  title = {Musical Instrument Identification: {{A}} Pattern-Recognition Approach},
  shorttitle = {Musical Instrument Identification},
  author = {Martin, Keith D. and Kim, Youngmoo E.},
  date = {1998-09-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {104},
  pages = {1768--1768},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.424083},
  url = {https://pubs.aip.org/jasa/article/104/3_Supplement/1768/558739/Musical-instrument-identification-A-pattern},
  urldate = {2024-05-07},
  abstract = {A statistical pattern-recognition technique was applied to the classification of musical instrument tones within a taxonomic hierarchy. Perceptually salient acoustic features—related to the physical properties of source excitation and resonance structure—were measured from the output of an auditory model (the log-lag correlogram) for 1023 isolated tones over the full pitch ranges of 15 orchestral instruments. The data set included examples from the string (bowed and plucked), woodwind (single, double, and air reed), and brass families. Using 70\%/30\% splits between training and test data, maximum a\hphantom{,}posteriori classifiers were constructed based on Gaussian models arrived at through Fisher multiple-discriminant analysis. The classifiers distinguished transient from continuant tones with approximately 99\% correct performance. Instrument families were identified with approximately 90\% performance, and individual instruments were identified with an overall success rate of approximately 70\%. These preliminary analyses compare favorably with human performance on the same task and demonstrate the utility of the hierarchical approach to classification.},
  issue = {3\_Supplement},
  langid = {english}
}

@inproceedings{moral2007,
  title = {Long-Time-Average-Spectra of Scales and Spectra of Single Tones from a Violin},
  author = {Moral, A.},
  date = {2007},
  url = {https://www.semanticscholar.org/paper/Long-time-average-spectra-of-scales-and-spectra-of-Moral/a3ae4ee2b9a853d368e9e39f9108a9b40c37e017},
  urldate = {2024-07-15},
  abstract = {Long-Time-Average-Spectra, LTAS:es, have proved to give representative records of violins. The fulltime scales recorded in a reverberation chamber have, however, not been well suited for listening tests. Therefore in this investigation the recordings were made in an anechoic chamber and the effects on the LTAS by reducing the number of tones played were tried. Furthermore, the relations were investigated between Single-Tone -Spectra, STS :es, and LTAS:es. The investigations show that a representative LTAS of a violin can be obtained from every third tone on the two middle strings. Furthermore, i t shows that the spectrum level of all strings a r e approximately equal to 12 Bark and thereafter it drops 4 dB from a string to the next lower and that the high frequency limit of each string drops one Bark from one string to the next lower string. The levels of the STS:es fall in general within f 5 dB of the LTAS of the same string.}
}

@article{muckenhirn2017,
  title = {Long-{{Term Spectral Statistics}} for {{Voice Presentation Attack Detection}}},
  author = {Muckenhirn, Hannah and Korshunov, Pavel and Magimai-Doss, Mathew and Marcel, Sebastien},
  date = {2017-11},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  shortjournal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
  volume = {25},
  number = {11},
  pages = {2098--2111},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2017.2743340},
  url = {http://ieeexplore.ieee.org/document/8015145/},
  urldate = {2024-08-30},
  abstract = {Automatic speaker verification systems can be spoofed through recorded, synthetic or voice converted speech of target speakers. To make these systems practically viable, the detection of such attacks, referred to as presentation attacks, is of paramount interest. In that direction, this paper investigates two aspects: (a) a novel approach to detect presentation attacks where, unlike conventional approaches, no speech signal modeling related assumptions are made, rather the attacks are detected by computing first order and second order spectral statistics and feeding them to a classifier, and (b) generalization of the presentation attack detection systems across databases. Our investigations on ASVspoof 2015 challenge database and AVspoof database show that, when compared to the approaches based on conventional short-term spectral features, the proposed approach with a linear discriminative classifier yields a better system, irrespective of whether the spoofed signal is replayed to the microphone or is directly injected into the system software process. Cross-database investigations show that neither the short-term spectral processing based approaches nor the proposed approach yield systems which are able to generalize across databases or methods of attack. Thus, revealing the difficulty of the problem and the need for further resources and research.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/5I6J7768/Muckenhirn et al. - 2017 - Long-Term Spectral Statistics for Voice Presentati.pdf}
}

@article{rozzi2022,
  title = {A Listening Experiment Comparing the Timbre of Two {{Stradivari}} with Other Violins},
  author = {Rozzi, Carlo Andrea and Voltini, Alessandro and Antonacci, Fabio and Nucci, Massimo and Grassi, Massimo},
  date = {2022-01-26},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {151},
  number = {1},
  pages = {443--450},
  issn = {0001-4966},
  doi = {10.1121/10.0009320},
  url = {https://doi.org/10.1121/10.0009320},
  urldate = {2024-12-10},
  abstract = {The violins of Stradivari are recognized worldwide as an excellence in craftsmanship, a model for instrument makers, and an unachievable desire for collectors and players. However, despite the myth surrounding these instruments, blindfolded players tendentially prefer to play modern violins. Here, we present a double blind listening experiment aimed at analyzing and comparatively rating the sound timbre of violins. The mythic instruments were listened to among other well regarded and not so well regarded violins. 70 listeners (violin makers of the Cremona area) rated the timbre difference between the simple musical scales played on a test and a reference violin, and the results showed that their preference converged on one particular Stradivari. The acoustical measurements revealed some similarities between the subjective ratings and the physical characteristics of the violins. It is speculated that the myth of Stradivari could have been boosted, among other factors, by the specimens of tonal superior quality, which biased favourably the judgment on his instruments and spread on all of the maker's production. These results contribute to the understanding of the timbre of violins and suggest the characteristics that are in a relationship with the pleasantness of the timbre.},
  file = {/home/hugo/Zotero/storage/JD62KPE5/Rozzi et al. - 2022 - A listening experiment comparing the timbre of two Stradivari with other violins.pdf;/home/hugo/Zotero/storage/KFXN2HDS/A-listening-experiment-comparing-the-timbre-of-two.html}
}

@inproceedings{setragno2017a,
  title = {Feature-{{Based Timbral Characterization}} of {{Historical}} and {{Modern Violins}}},
  author = {Setragno, F. and Zanoni, M. and Antonacci, F. and Sarti, A.},
  date = {2017},
  url = {https://www.semanticscholar.org/paper/Feature-Based-Timbral-Characterization-of-and-Setragno-Zanoni/84971ffe04917aada0de142400b5333ed01f5f95},
  urldate = {2024-04-24},
  abstract = {Violin timbre is a very complex case of study. The sound properties that distinguish an historical violin from a modern one are still not clear. The purpose of this study is to understand what are these properties, by means of feature-based analysis. We extract audio features related to timbre and we exploit feature selection techniques in order to investigate what are the most characterizing ones. We compare different feature selection algorithms and we illustrate how we applied their outcome to a classification task with historical and modern instruments. Results show that the classification performance improves when using the selected features.},
  keywords = {printed,read},
  file = {/home/hugo/Zotero/storage/DAV99MI7/Setragno et al. - 2017 - Feature-Based Timbral Characterization of Historic.pdf}
}

@incollection{simmermacher2006,
  title = {Feature {{Analysis}} and {{Classification}} of {{Classical Musical Instruments}}: {{An Empirical Study}}},
  shorttitle = {Feature {{Analysis}} and {{Classification}} of {{Classical Musical Instruments}}},
  booktitle = {Advances in {{Data Mining}}. {{Applications}} in {{Medicine}}, {{Web Mining}}, {{Marketing}}, {{Image}} and {{Signal Mining}}},
  author = {Simmermacher, Christian and Deng, Da and Cranefield, Stephen},
  editor = {Perner, Petra},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2006},
  volume = {4065},
  pages = {444--458},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11790853_35},
  url = {http://link.springer.com/10.1007/11790853_35},
  urldate = {2025-01-10},
  abstract = {We present an empirical study on classical music instrument classification. A methodology with feature extraction and evaluation is proposed and assessed with a number of experiments, whose final stage is to detect instruments in solo passages. In feature selection it is found that similar but different rankings for individual tone classification and solo passage instrument recognition are reported. Based on the feature selection results, excerpts from concerto and sonata files are processed, so as to detect and distinguish four major instruments in solo passages: trumpet, flute, violin, and piano. Nineteen features selected from the Mel-frequency cepstral coefficients (MFCC) and the MPEG-7 audio descriptors achieve a recognition rate of around 94\% by the best classifier assessed by cross validation.},
  isbn = {978-3-540-36036-0 978-3-540-36037-7},
  langid = {english},
  file = {/home/hugo/Zotero/storage/4PZWSG4T/Simmermacher et al. - 2006 - Feature Analysis and Classification of Classical Musical Instruments An Empirical Study.pdf}
}

@article{wang2020,
  title = {Individual {{Violin Recognition Method Combining Tonal}} and {{Nontonal Features}}},
  author = {Wang, Qi and Bao, Changchun},
  date = {2020-06},
  journaltitle = {Electronics},
  volume = {9},
  number = {6},
  pages = {950},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics9060950},
  url = {https://www.mdpi.com/2079-9292/9/6/950},
  urldate = {2023-10-16},
  abstract = {Individual recognition among instruments of the same type is a challenging problem and it has been rarely investigated. In this study, the individual recognition of violins is explored. Based on the source–filter model, the spectrum can be divided into tonal content and nontonal content, which reflects the timbre from complementary aspects. The tonal/nontonal gammatone frequency cepstral coefficients (GFCC) are combined to describe the corresponding spectrum contents in this study. In the recognition system, Gaussian mixture models–universal background model (GMM–UBM) is employed to parameterize the distribution of the combined features. In order to evaluate the recognition task of violin individuals, a solo dataset including 86 violins is developed in this study. Compared with other features, the combined features show a better performance in both individual violin recognition and violin grade classification. Experimental results also show the GMM–UBM outperforms the CNN, especially when the training data are limited. Finally, the effect of players on the individual violin recognition is investigated.},
  issue = {6},
  langid = {english},
  keywords = {Gaussian mixture models–universal background model,Identification,individual violin recognition,printed,read,tonal/nontonal content,violin grade classification},
  file = {/home/hugo/Zotero/storage/XFSLR2HY/Wang and Bao - 2020 - Individual Violin Recognition Method Combining Ton.pdf}
}

@incollection{wrzeciono2010,
  title = {Violin {{Sound Quality}}: {{Expert Judgements}} and {{Objective Measurements}}},
  shorttitle = {Violin {{Sound Quality}}},
  booktitle = {Advances in {{Music Information Retrieval}}},
  author = {Wrzeciono, Piotr and Marasek, Krzysztof},
  editor = {Raś, Zbigniew W. and Wieczorkowska, Alicja A.},
  date = {2010},
  pages = {237--260},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-11674-2_11},
  url = {https://doi.org/10.1007/978-3-642-11674-2_11},
  urldate = {2024-10-08},
  abstract = {Searching for objective and subjective parameters is very important in automatic classification of multimedia databases containing recordings of musical instruments sounds. This paper describes these parameters and methods of obtaining them for a violin sound. The objective parameters are violin modes with their properties: frequency and mutual energy factor. The subjective parameter is evaluation of sound quality done by experts. Based on violin modes parameters, expert judgements and harmony perception, a sound quality classifier was created. The estimated value of sound quality evaluation is consistent with expert judgements for 75.5\% of instruments from AMATI multimedia database containing recordings of violins from 10th International Henryk Wieniawski Violin Maker Competition.},
  isbn = {978-3-642-11674-2},
  langid = {english},
  keywords = {Cross Correlation Function,Expert Judgement,Fundamental Frequency,Musical Instrument,Sound Quality},
  file = {/home/hugo/Zotero/storage/PTHD4PUI/Wrzeciono and Marasek - 2010 - Violin Sound Quality Expert Judgements and Objective Measurements.pdf}
}

@article{yokoyama2020,
  title = {Possibility of Distinction of Violin Timbre by Spectral Envelope},
  author = {Yokoyama, Masao},
  date = {2020-01-01},
  journaltitle = {Applied Acoustics},
  shortjournal = {Applied Acoustics},
  volume = {157},
  pages = {107006},
  issn = {0003-682X},
  doi = {10.1016/j.apacoust.2019.107006},
  url = {https://www.sciencedirect.com/science/article/pii/S0003682X19302403},
  urldate = {2024-05-22},
  abstract = {In this study, the sounds of violins, performed by a violinist, were recorded and the distribution of peak frequencies of the spectral envelope of the recorded sound data was analyzed. The distribution of peak frequencies is different for each violin, but some tendencies were found. Questionnaires were used to examine the distinction in violin timbre by the difference in the patterns of peak frequencies. When the patterns of the two violins were similar, the subjects responded that the timbre of both violins was similar than the other violin whose pattern of peak frequencies was different. The present study discussed the contribution of the similarity of patterns and the difference between patterns to the identification of the timbre.},
  keywords = {Detection,Musical acoustic,printed,read,Spectral envelop,Timbre,Violin},
  file = {/home/hugo/Zotero/storage/NUAQ2NYC/Yokoyama - 2020 - Possibility of distinction of violin timbre by spe.pdf}
}

@article{yokoyama2022a,
  title = {Identification of Violin Timbre by Neural Network Using Acoustic Features},
  author = {Yokoyama, Masao and Ishigaki, Yuya},
  date = {2022-12-22},
  journaltitle = {Proceedings of Meetings on Acoustics},
  shortjournal = {Proceedings of Meetings on Acoustics},
  volume = {49},
  number = {1},
  pages = {035004},
  issn = {1939-800X},
  doi = {10.1121/2.0001659},
  url = {https://doi.org/10.1121/2.0001659},
  urldate = {2024-04-24},
  abstract = {The timbre of violins is identified using machine learning, and a computer program is developed for the neural network using Python and Keras libraries. The 21 violins recorded include old Italian violins made by Stradivari and contemporary violins. The training and test data use the spectrum envelope and Mel-frequency cepstrum coefficients (MFCC). The accuracy of the identification test in the case of open strings is greater than 90\%. Furthermore, experiments that predict similarity in timbre of an unknown violin to that of trained violins are presented.},
  keywords = {printed,read},
  file = {/home/hugo/Zotero/storage/IV75LWDS/Yokoyama and Ishigaki - 2022 - Identification of violin timbre by neural network .pdf;/home/hugo/Zotero/storage/9YXMFXEZ/Identification-of-violin-timbre-by-neural-network.html}
}

@article{zanoni2017,
  title = {Towards {{Prediction}} of {{Violin Timbre}} from {{Vibrational Measurements}}},
  author = {Zanoni, Massimiliano and Antonacci, Fabio and Sarti, Augusto},
  date = {2017},
  abstract = {This contribution investigates on the acoustics of violin, and more specifically on the relationship existing between vibrational impulse responses and the timbre of the instrument. With respect to previous publications on this topic, we tackle the problem using a feature-based approach. More specifically, we aim at finding the correlation between the features extracted from accelerometric measurements of the bridge mobility and from audio recordings of a prescribed set of performances. Results demonstrate that features describing to the global shape of the spectrum are strongly related. On these descriptors we also show the possibility of predicting the features of audio recordings from the vibrational ones. Experimental data are based on a set of 25 modern violins.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/WKP2FWRB/Zanoni et al. - 2017 - Towards Prediction of Violin Timbre from Vibration.pdf}
}

@article{zhao2022,
  title = {Violinist {{Identification Using Note-Level Timbre Feature Distributions}}},
  author = {Zhao, Yudong and Fazekas, Gyorgy and Sandler, Mark},
  date = {2022-05-23},
  journaltitle = {ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {601--605},
  publisher = {IEEE},
  location = {Singapore, Singapore},
  doi = {10.1109/ICASSP43922.2022.9747606},
  url = {https://ieeexplore.ieee.org/document/9747606/},
  urldate = {2024-04-24},
  abstract = {Modelling musical performers’ individual playing styles based on audio features is important for music education, music expression analysis and music generation. In violin performance, the perception of playing styles are mainly affected by the characteristic musical timbre, which is mostly determined by performers, instruments and recording conditions. To verify if timbre features can describe a performer’s style adequately, we examine a violinist identification method based on note-level timbre feature distributions. We first apply it using solo datasets to recognise professional violinists, then use it to identify master players from commercial concerto recordings. The results show that the designed features and method work very well for both datasets. The identification accuracy with the solo dataset using MFCCs and spectral constrast features are 0.94 and 0.91 respectively. Significantly lower but promising results are reported with the concerto dataset. Results suggest that the selected timbre features can model performers’ individual playing reasonably objectively, regardless of the instrument they play.},
  eventtitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {9781665405409},
  keywords = {printed,read},
  file = {/home/hugo/Zotero/storage/3L9RTE5Y/Zhao et al. - 2022 - Violinist Identification Using Note-Level Timbre F.pdf}
}
