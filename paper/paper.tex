\documentclass[letterpaper,11pt,leqno]{article}
\usepackage{paper}
\usepackage{tikz}
\usetikzlibrary{arrows,positioning,shapes}
\bibliographystyle{bibliography}

% Enter paper title to populate the PDF metadata:
\hypersetup{pdftitle={Minimalist LaTeX Template for Academic Papers}}

% Enter BibTeX file with references:
\newcommand{\bib}{bibliography.bib}

% Enter PDF file with figures:
\newcommand{\pdf}{figures.pdf}

\begin{document}

% Enter title:
\title{Individual Violin Identification using audio features and machine learning}

% Enter authors:
\author{Hugo Pauget Ballesteros, Claudia Fritz
%
% Enter affiliations and acknowledgements:
\thanks{First Author: First University. Second Author: Second University. We thank colleagues for helpful comments and discussions. This work was supported by a grant [grant number]; another grant [grant number]; and a foundation.}}

% Enter date:
\date{June 2024}   

\begin{titlepage}
\maketitle

% Enter abstract:
This is the abstract. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.

\end{titlepage}

% Enter main text:
\section{Introduction}\label{s:introduction}
 
Musical instruments classification is a Musical Information Retrieval (MIR) task which consists of determining the instruments present in a recording. This topic has been extensively studied in the literature, and for monophonic recordings (containing only one instrument), state-of-the-art models reach often almost $100\%$. However, few articles have addressed the issue of identifying individual instruments of the same type.

In \cite{zhaoViolinistIdentificationUsing2022}

This paper is structured as follows: Section \ref{s:methodology} presents the methodology of our experiment, describing data collection, features extraction, data exploration and finally classification using machine learning methods. Results of the experiments are discussed in Section \ref{s:results}. Finally, conlusions are drawn in Section \ref*{s:conclusions}, which also outlines possible future developments. 

\section{Methodology}\label{s:methodology}

\subsection{Dataset}

During the Bilbao Project, thirteen violins were built in order to relate their material and geometrical characteristics with their tonal quality \citep{fritzBilbaoProjectSearching2021}. These violins have been played by twenty-three professional violinists, each of them having recorded a scale on each violin. The recordings were made under the same conditions in a large rehearsal room at the Bilbao conservatory, keeping the distance between the player and the microphone constant. Our dataset thus consists of $13 \times 23$ scales.

\subsection{Features}

The following features have been compared for the classification task :

\paragraph*{Long-Term Average Spectra (LTAS)}{
	Average Power Spectral Density (PSD) of a recording, obtained using a series of overlapping FFTs.
}

\paragraph*{1/3-octave band LTAS (1/3-LTAS)}{
	LTAS, gaussian-smoothed to 1/3-octave resolution.
}

\paragraph{Mel-Frenquency Cepstral Coefficients (MFCC)}{
	MFCC are a set of features that has been extensively used for Automatic Speaker Reognition and for Instruments Classification.
	\begin{figure}[!h]
		\begin{tikzpicture}
			% \usetikzlibrary{arrows,positioning,shapes}
			\tikzstyle{block} = [rectangle, draw, text width=3em, text centered, rounded corners, minimum height=3em]
			\tikzstyle{arrow} = [draw, -latex']
			\node [block] (signal) {Signal};
			\node [block, right=of signal] (fft) {FFT};
			\node [block, right=of fft] (mel) {Mel \\ Filter};
			\node [block, right=of mel] (log) {Log};
			\node [block, right=of log] (dct) {DCT};
			\node [block, right=of dct] (mfcc) {MFCC};

			\path[draw,->] (signal) edge (fft);
			\path[draw,->] (fft) edge (mel);
			\path[draw,->] (mel) edge (log);
			\path[draw,->] (log) edge (dct);
			\path[draw,->] (dct) edge (mfcc);
		\end{tikzpicture}
	\end{figure}
}

\paragraph*{Long-Term Cepstral Coefficients (LTCC)}{
	LTCC have been introduced in \cite{lukasikLongTermCepstral2010b} for Indivudial Instrument Identification. Their calculation is similar to that of MFCCs, except that a Mel-filterbank is not applied and that the final step is given by an Inverse Discrete Fourier Transform.

	\begin{figure}[!h]
		\begin{tikzpicture}
			\tikzstyle{block} = [rectangle, draw, text width=3em, text centered, rounded corners, minimum height=3em]
			\tikzstyle{arrow} = [draw, -latex']
			\node [block] (signal) {Signal};
			\node [block, right=of signal] (fft) {FFT};
			\node [block, right=of fft] (abs) {$|.|$};
			\node [block, right=of abs] (log) {Log};
			\node [block, right=of log] (idft) {iDFT};
			\node [block, right=of idft] (ltcc) {LTCC};

			\path[draw,->] (signal) edge (fft);
			\path[draw,->] (fft) edge (abs);
			\path[draw,->] (abs) edge (log);
			\path[draw,->] (log) edge (idft);
			\path[draw,->] (idft) edge (ltcc);
		\end{tikzpicture}
	\end{figure}
}

\subsection{Data exploration}

\subsection{Classification}

\section{Results}\label{s:results}

\section{Conclusions}\label{s:conclusions}



\bibliography{\bib}

\end{document}